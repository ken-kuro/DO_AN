{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Resume Text Column to Prepare for matching - first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from time import strptime\n",
    "\n",
    "import RAKE as rake\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################\n",
    "## Working on Resume data\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First reading my resume csv\n",
    "resume = pd.read_csv('wip/resume_sorted5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14428 entries, 0 to 14427\n",
      "Data columns (total 26 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   index                   14428 non-null  int64 \n",
      " 1   Resume_title            14428 non-null  object\n",
      " 2   City                    14428 non-null  object\n",
      " 3   location                14428 non-null  int64 \n",
      " 4   Description             14428 non-null  object\n",
      " 5   work_experiences        14428 non-null  object\n",
      " 6   Educations              14428 non-null  object\n",
      " 7   Skills                  14428 non-null  object\n",
      " 8   Links                   14428 non-null  object\n",
      " 9   Certificates            14428 non-null  object\n",
      " 10  Additional Information  14428 non-null  object\n",
      " 11  is_grad                 14428 non-null  int64 \n",
      " 12  is_postgrad             14428 non-null  int64 \n",
      " 13  is_doc                  14428 non-null  int64 \n",
      " 14  edu_unknown             14428 non-null  int64 \n",
      " 15  Computer_Eng            14428 non-null  int64 \n",
      " 16  Finance                 14428 non-null  int64 \n",
      " 17  HR                      14428 non-null  int64 \n",
      " 18  AI_stats                14428 non-null  int64 \n",
      " 19  MBA                     14428 non-null  int64 \n",
      " 20  Other_specialization    14428 non-null  int64 \n",
      " 21  resume_id               14428 non-null  int64 \n",
      " 22  total_experience        14428 non-null  int64 \n",
      " 23  experience_range        14428 non-null  int64 \n",
      " 24  loc_name                14428 non-null  object\n",
      " 25  experience_desc         14428 non-null  object\n",
      "dtypes: int64(15), object(11)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#initial info\n",
    "resume.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################\n",
    "## To match resume with jobs, I need to have similar 20 vectors, that I created to train my Doc2Vec model for jobs. \n",
    "\n",
    "### For training my jobs model, I picked  text data from :\n",
    "* job title\n",
    "* job description\n",
    "* skills\n",
    "* industry\n",
    "\n",
    "### So for training my resume model, I need similar text, thus picking:\n",
    "* Resume_title\n",
    "* Resume description \n",
    "* skills\n",
    "* Additional Information\n",
    "\n",
    "\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume['Resume_title'] = resume['Resume_title'].str.lower()\n",
    "resume['Skills']=resume['Skills'].str.lower()\n",
    "resume['Description'] = resume['Description'].str.lower()\n",
    "resume['Additional Information'] = resume['Additional Information'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume['Description'].replace('none', ' ',inplace=True)\n",
    "resume['Additional Information'].replace('none', ' ',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_id</th>\n",
       "      <th>Resume_title</th>\n",
       "      <th>resume_combo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>java developer</td>\n",
       "      <td>java developer to prove myself dedicated, wort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>software developer</td>\n",
       "      <td>software developer working as software develop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>java developer</td>\n",
       "      <td>java developer looking for a challenging caree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>seeking innovative and challenging career assi...</td>\n",
       "      <td>seeking innovative and challenging career assi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>java developer</td>\n",
       "      <td>java developer   ['project: hr payroll systems...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resume_id                                       Resume_title  \\\n",
       "0          0                                     java developer   \n",
       "1          1                                 software developer   \n",
       "2          2                                     java developer   \n",
       "3          3  seeking innovative and challenging career assi...   \n",
       "4          4                                     java developer   \n",
       "\n",
       "                                        resume_combo  \n",
       "0  java developer to prove myself dedicated, wort...  \n",
       "1  software developer working as software develop...  \n",
       "2  java developer looking for a challenging caree...  \n",
       "3  seeking innovative and challenging career assi...  \n",
       "4  java developer   ['project: hr payroll systems...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resume = resume[['resume_id','Resume_title' ]]\n",
    "df_resume['resume_combo'] = resume['Resume_title'] +\" \" + resume['Description'] +\" \" + resume['Skills'] + \" \"+resume['Additional Information'] + \" \"+resume['experience_desc']\n",
    "df_resume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    java developer to prove myself dedicated, wort...\n",
       "1    software developer working as software develop...\n",
       "2    java developer looking for a challenging caree...\n",
       "3    seeking innovative and challenging career assi...\n",
       "4    java developer   ['project: hr payroll systems...\n",
       "5    java developer   ['java']   ['have the potenti...\n",
       "6    java developer to secure a challenging positio...\n",
       "7    searching job for java developer   ['c++', ' h...\n",
       "8    mca / with 3 years of development experience •...\n",
       "9    java developer attain the position of 'java de...\n",
       "Name: resume_combo, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = df_resume['resume_combo']\n",
    "docs_sample = docs.head(10)\n",
    "docs_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import all the dependencies\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "set(stopwords.words('english'))\n",
    "\n",
    "import string\n",
    "\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ëœ'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14428, 70688)\n",
      "(14428, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.append('ã¯æ’ëœ')\n",
    "stopwords.append('\\n')\n",
    "stopwords.append('•')\n",
    "#Transforms words to TFIDF\n",
    "vectorizer = TfidfVectorizer(stop_words = stopwords)\n",
    "\n",
    "index = 0\n",
    "keys = {}\n",
    "\n",
    "for rem in df_resume.itertuples() :\n",
    "    key = rem[1]\n",
    "    keys[key] = index\n",
    "    index += 1\n",
    "\n",
    "#Fit the vectorizer to the data\n",
    "vectorizer.fit(df_resume['resume_combo'].fillna(''))\n",
    "\n",
    "#Transform the data\n",
    "tfidf_scores = vectorizer.transform(df_resume['resume_combo'].fillna(''))\n",
    "\n",
    "print(tfidf_scores.shape)\n",
    "print(df_resume.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(tfidf_scores.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00089765</th>\n",
       "      <th>00089805</th>\n",
       "      <th>000webhostapp</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>003</th>\n",
       "      <th>00353</th>\n",
       "      <th>...</th>\n",
       "      <th>õle</th>\n",
       "      <th>øcreated</th>\n",
       "      <th>ǁǁǁǁǁǁ</th>\n",
       "      <th>ηadoop</th>\n",
       "      <th>τrain</th>\n",
       "      <th>τοοls</th>\n",
       "      <th>чєαr</th>\n",
       "      <th>ﬁled</th>\n",
       "      <th>ﬁnancial</th>\n",
       "      <th>ﬁxing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70688 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0000  00089765  00089805  000webhostapp  001  002  003  00353  \\\n",
       "0  0.0  0.0   0.0       0.0       0.0            0.0  0.0  0.0  0.0    0.0   \n",
       "1  0.0  0.0   0.0       0.0       0.0            0.0  0.0  0.0  0.0    0.0   \n",
       "2  0.0  0.0   0.0       0.0       0.0            0.0  0.0  0.0  0.0    0.0   \n",
       "3  0.0  0.0   0.0       0.0       0.0            0.0  0.0  0.0  0.0    0.0   \n",
       "4  0.0  0.0   0.0       0.0       0.0            0.0  0.0  0.0  0.0    0.0   \n",
       "\n",
       "   ...  õle  øcreated  ǁǁǁǁǁǁ  ηadoop  τrain  τοοls  чєαr  ﬁled  ﬁnancial  \\\n",
       "0  ...  0.0       0.0     0.0     0.0    0.0    0.0   0.0   0.0       0.0   \n",
       "1  ...  0.0       0.0     0.0     0.0    0.0    0.0   0.0   0.0       0.0   \n",
       "2  ...  0.0       0.0     0.0     0.0    0.0    0.0   0.0   0.0       0.0   \n",
       "3  ...  0.0       0.0     0.0     0.0    0.0    0.0   0.0   0.0       0.0   \n",
       "4  ...  0.0       0.0     0.0     0.0    0.0    0.0   0.0   0.0       0.0   \n",
       "\n",
       "   ﬁxing  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 70688 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating my Stopword list\n",
    "#### As seen there are so many unwanted tokens like numbers,ïƒ¼ etc , I need to add them in \"stop words\" list to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting list of all tokens\n",
    "word_list = test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Getting a list of unwanted words as s_words and adding to stopwords\n",
    "s_words =[]\n",
    "for word in word_list:\n",
    "    #print(word)\n",
    "    if re.search(\"^\\W|^\\d\",word):\n",
    "        s_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_words.append('')        \n",
    "from nltk.corpus import stopwords\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "stopword_set = list(stopword_set)\n",
    "stopword_set.extend(s_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    stop_words = stopword_set\n",
    "    #0. split words by whitespace\n",
    "    text = text.split()\n",
    "    \n",
    "    \n",
    "    # 1. lower case\n",
    "    text = [word.lower() for word in text]\n",
    "    \n",
    "    # 2. remove punctuations\n",
    "    punc_table = str.maketrans('','',string.punctuation)\n",
    "    text = [word.translate(punc_table) for word in text]\n",
    "    \n",
    "    # 3. remove stop words\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_doc = []\n",
    "doc = df_resume['resume_combo']\n",
    "#doc = docs_sample\n",
    "for d in doc:\n",
    "    tokenized_doc.append(preprocess(d))\n",
    "#tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokenized document into gensim formated tagged data\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14428"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_doc = len(tagged_data)\n",
    "num_doc\n",
    "#confirm length (should be 14428)\n",
    "len(tokenized_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self, path_prefix):\n",
    "        self.path_prefix = path_prefix\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        output_path = get_tmpfile('{}_epoch{}.model'.format(self.path_prefix, self.epoch))\n",
    "        model.save(output_path)\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load saved doc2vec model\n",
    "model= Doc2Vec.load(\"Model/my_doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get vector value\n",
    "vec = np.empty([14428,20])\n",
    "\n",
    "for k,i in enumerate(tokenized_doc):\n",
    "    \n",
    "    #print(i)\n",
    "    vector = model.infer_vector(i)\n",
    "    vec[k] = vector\n",
    "    #vec = np.append(vector)\n",
    "    #vecf = np.append(vec,vector)\n",
    "\n",
    "# reshape into 2D\n",
    "new_arr = np.reshape(vec,(-1,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = range(1, 21)\n",
    "vec_df = pd.DataFrame(new_arr, columns=['vec_' + str(i) for i in rng])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vec_1</th>\n",
       "      <th>vec_2</th>\n",
       "      <th>vec_3</th>\n",
       "      <th>vec_4</th>\n",
       "      <th>vec_5</th>\n",
       "      <th>vec_6</th>\n",
       "      <th>vec_7</th>\n",
       "      <th>vec_8</th>\n",
       "      <th>vec_9</th>\n",
       "      <th>vec_10</th>\n",
       "      <th>vec_11</th>\n",
       "      <th>vec_12</th>\n",
       "      <th>vec_13</th>\n",
       "      <th>vec_14</th>\n",
       "      <th>vec_15</th>\n",
       "      <th>vec_16</th>\n",
       "      <th>vec_17</th>\n",
       "      <th>vec_18</th>\n",
       "      <th>vec_19</th>\n",
       "      <th>vec_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.145642</td>\n",
       "      <td>-0.409380</td>\n",
       "      <td>0.701160</td>\n",
       "      <td>-0.938745</td>\n",
       "      <td>0.585239</td>\n",
       "      <td>3.585946</td>\n",
       "      <td>-0.120781</td>\n",
       "      <td>0.111222</td>\n",
       "      <td>1.644105</td>\n",
       "      <td>2.184981</td>\n",
       "      <td>-2.117909</td>\n",
       "      <td>-0.085430</td>\n",
       "      <td>-2.877392</td>\n",
       "      <td>0.239383</td>\n",
       "      <td>-1.582871</td>\n",
       "      <td>1.435642</td>\n",
       "      <td>-1.051450</td>\n",
       "      <td>1.960831</td>\n",
       "      <td>1.786694</td>\n",
       "      <td>-2.375981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.786235</td>\n",
       "      <td>-1.306011</td>\n",
       "      <td>-1.383107</td>\n",
       "      <td>-1.669708</td>\n",
       "      <td>0.832136</td>\n",
       "      <td>1.849790</td>\n",
       "      <td>0.178872</td>\n",
       "      <td>-1.736894</td>\n",
       "      <td>0.741685</td>\n",
       "      <td>1.553933</td>\n",
       "      <td>-2.916478</td>\n",
       "      <td>-0.712572</td>\n",
       "      <td>-0.502129</td>\n",
       "      <td>-0.849293</td>\n",
       "      <td>0.435406</td>\n",
       "      <td>0.339330</td>\n",
       "      <td>0.060282</td>\n",
       "      <td>-0.415035</td>\n",
       "      <td>3.203696</td>\n",
       "      <td>-3.607635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.747642</td>\n",
       "      <td>-1.721797</td>\n",
       "      <td>-0.910322</td>\n",
       "      <td>-0.775950</td>\n",
       "      <td>1.472325</td>\n",
       "      <td>2.455998</td>\n",
       "      <td>-0.852150</td>\n",
       "      <td>-0.150517</td>\n",
       "      <td>0.844202</td>\n",
       "      <td>1.380623</td>\n",
       "      <td>-1.018832</td>\n",
       "      <td>0.777981</td>\n",
       "      <td>-1.977556</td>\n",
       "      <td>0.853214</td>\n",
       "      <td>-1.281344</td>\n",
       "      <td>2.195391</td>\n",
       "      <td>0.800305</td>\n",
       "      <td>1.078035</td>\n",
       "      <td>2.166900</td>\n",
       "      <td>-2.658121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.771770</td>\n",
       "      <td>-1.375850</td>\n",
       "      <td>-0.475922</td>\n",
       "      <td>-0.784473</td>\n",
       "      <td>-0.377240</td>\n",
       "      <td>1.596389</td>\n",
       "      <td>1.094220</td>\n",
       "      <td>-0.253642</td>\n",
       "      <td>0.468265</td>\n",
       "      <td>2.149588</td>\n",
       "      <td>-1.234415</td>\n",
       "      <td>0.295536</td>\n",
       "      <td>-2.615532</td>\n",
       "      <td>0.115959</td>\n",
       "      <td>-2.044196</td>\n",
       "      <td>-0.769109</td>\n",
       "      <td>-0.716604</td>\n",
       "      <td>1.145388</td>\n",
       "      <td>3.452934</td>\n",
       "      <td>-1.008162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.097372</td>\n",
       "      <td>-1.405603</td>\n",
       "      <td>-0.801234</td>\n",
       "      <td>-0.248921</td>\n",
       "      <td>-0.376417</td>\n",
       "      <td>-0.157050</td>\n",
       "      <td>-0.290440</td>\n",
       "      <td>-1.440582</td>\n",
       "      <td>-0.169669</td>\n",
       "      <td>1.190537</td>\n",
       "      <td>-0.291407</td>\n",
       "      <td>-1.080500</td>\n",
       "      <td>-2.950497</td>\n",
       "      <td>0.031693</td>\n",
       "      <td>0.119182</td>\n",
       "      <td>-0.883555</td>\n",
       "      <td>0.178819</td>\n",
       "      <td>-0.858324</td>\n",
       "      <td>1.239632</td>\n",
       "      <td>-0.043914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      vec_1     vec_2     vec_3     vec_4     vec_5     vec_6     vec_7  \\\n",
       "0 -3.145642 -0.409380  0.701160 -0.938745  0.585239  3.585946 -0.120781   \n",
       "1 -0.786235 -1.306011 -1.383107 -1.669708  0.832136  1.849790  0.178872   \n",
       "2 -2.747642 -1.721797 -0.910322 -0.775950  1.472325  2.455998 -0.852150   \n",
       "3 -1.771770 -1.375850 -0.475922 -0.784473 -0.377240  1.596389  1.094220   \n",
       "4 -0.097372 -1.405603 -0.801234 -0.248921 -0.376417 -0.157050 -0.290440   \n",
       "\n",
       "      vec_8     vec_9    vec_10    vec_11    vec_12    vec_13    vec_14  \\\n",
       "0  0.111222  1.644105  2.184981 -2.117909 -0.085430 -2.877392  0.239383   \n",
       "1 -1.736894  0.741685  1.553933 -2.916478 -0.712572 -0.502129 -0.849293   \n",
       "2 -0.150517  0.844202  1.380623 -1.018832  0.777981 -1.977556  0.853214   \n",
       "3 -0.253642  0.468265  2.149588 -1.234415  0.295536 -2.615532  0.115959   \n",
       "4 -1.440582 -0.169669  1.190537 -0.291407 -1.080500 -2.950497  0.031693   \n",
       "\n",
       "     vec_15    vec_16    vec_17    vec_18    vec_19    vec_20  \n",
       "0 -1.582871  1.435642 -1.051450  1.960831  1.786694 -2.375981  \n",
       "1  0.435406  0.339330  0.060282 -0.415035  3.203696 -3.607635  \n",
       "2 -1.281344  2.195391  0.800305  1.078035  2.166900 -2.658121  \n",
       "3 -2.044196 -0.769109 -0.716604  1.145388  3.452934 -1.008162  \n",
       "4  0.119182 -0.883555  0.178819 -0.858324  1.239632 -0.043914  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_resume = pd.concat([resume, vec_df], axis=1)\n",
    "con_resume.to_csv('wip/con_resume.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con_resume.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_doc = []\n",
    "#doc = df_resume['resume_combo']\n",
    "doc = docs_sample\n",
    "for d in doc:\n",
    "    tokenized_doc.append(preprocess(d))\n",
    "#tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokenized document into gensim formated tagged data\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_doc = len(tagged_data)\n",
    "num_doc\n",
    "#confirm length (should be 38941)\n",
    "len(tokenized_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load saved doc2vec model\n",
    "model= Doc2Vec.load(\"my_doc2vec.model\")\n",
    "\n",
    "## Get vector value\n",
    "vec = np.empty([10,20])\n",
    "\n",
    "for k,i in enumerate(tokenized_doc):\n",
    "    \n",
    "    #print(i)\n",
    "    vector = model.infer_vector(i)\n",
    "    vec[k] = vector\n",
    "    #vec = np.append(vector)\n",
    "    #vecf = np.append(vec,vector)\n",
    "\n",
    "# reshape into 2D\n",
    "new_arr = np.reshape(vec,(-1,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[1,2,3],[4,5,6]])\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.14492106, -0.41021681,  0.70149601, -0.93887955,  0.58496076,\n",
       "        3.58589458, -0.12033088,  0.11019378,  1.64519656,  2.18371987,\n",
       "       -2.11720061, -0.08485675, -2.87654066,  0.24021174, -1.58367932,\n",
       "        1.43522847, -1.05121636,  1.96061814,  1.78778028, -2.37729073])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = range(1, 21)\n",
    "vec_df = pd.DataFrame(new_arr, columns=['vec_' + str(i) for i in rng])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 20 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   vec_1   10 non-null     float64\n",
      " 1   vec_2   10 non-null     float64\n",
      " 2   vec_3   10 non-null     float64\n",
      " 3   vec_4   10 non-null     float64\n",
      " 4   vec_5   10 non-null     float64\n",
      " 5   vec_6   10 non-null     float64\n",
      " 6   vec_7   10 non-null     float64\n",
      " 7   vec_8   10 non-null     float64\n",
      " 8   vec_9   10 non-null     float64\n",
      " 9   vec_10  10 non-null     float64\n",
      " 10  vec_11  10 non-null     float64\n",
      " 11  vec_12  10 non-null     float64\n",
      " 12  vec_13  10 non-null     float64\n",
      " 13  vec_14  10 non-null     float64\n",
      " 14  vec_15  10 non-null     float64\n",
      " 15  vec_16  10 non-null     float64\n",
      " 16  vec_17  10 non-null     float64\n",
      " 17  vec_18  10 non-null     float64\n",
      " 18  vec_19  10 non-null     float64\n",
      " 19  vec_20  10 non-null     float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 1.7 KB\n"
     ]
    }
   ],
   "source": [
    "vec_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1.to_csv('test_r.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = resume.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read each work experience\n",
    "resume['work_experiences'] = resume['work_experiences'].str.lower()\n",
    "\n",
    "resume_all_desc = []\n",
    "for index, rows in resume.iterrows():\n",
    "    #print('#@#@#@#@#@@#@#@#@#@##@@#@#@@##@#@#@#@#@#@##@#@#@##@#@@#@#@#')\n",
    "    #print(f'resume no. {index}')\n",
    "    resume_desc= []\n",
    "    #pick work experience col and read it as JSON \n",
    "    \n",
    "    work = resume['work_experiences'][index]\n",
    "    try: result_work = eval(work)\n",
    "    except: continue\n",
    "    #print(f'resume  :  {index}')\n",
    "    #read description to match with job\n",
    "    \n",
    "    for i in result_work:    \n",
    "        w_title_n = (result_work[0][0]['wtitle:'])            \n",
    "        w_company= (result_work[i][1]['wcompany:'])\n",
    "#         resume_desc.append(w_company) \n",
    "        w_city= (result_work[i][2]['wcity:'])\n",
    "        w_state= (result_work[i][3]['wstate:'])\n",
    "        w_duration= (result_work[i][4]['wduration:'])\n",
    "           \n",
    "        w_descr= (result_work[i][5]['wdescr:'])\n",
    "        if  (w_descr == 'none'):\n",
    "            continue\n",
    "        #print(w_descr)\n",
    "        #print('**************')\n",
    "        resume_desc.append(w_descr + '')   \n",
    "        \n",
    "    #print(resume_desc)\n",
    "    resume_all_desc.append(resume_desc)\n",
    "#print(resume_test)\n",
    "resume['experience_desc'] = resume_all_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resume.to_csv('wip/resume_sorted5.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
